{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project for rmrb - Part #[1]\n",
    "\n",
    "### Corpus construction, text cleaning and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import zipfile\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is using the notebook? Tim\n"
     ]
    }
   ],
   "source": [
    "# need to unpack the 7z files before proceeding\n",
    "user = input(\"Who is using the notebook? \")\n",
    "if user == \"Tim\":\n",
    "    corpus_name = \"/Users/timqzhang/Desktop/UChicago/MACSS_Spring_2020/content_local/rmrb/7z\"\n",
    "elif user == \"Linghui\":\n",
    "    corpus_name = \"/Users/linghuiwu/uchicago/courseworks/soci40133/rmrb/7z\"\n",
    "elif user == \"Minghao\":\n",
    "    corpus_name = \"to be filled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import jieba\n",
    "import re\n",
    "import string\n",
    "from zhon.hanzi import punctuation, stops, non_stops\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec, LineSentence\n",
    "import linecache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cores is 16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print('Number of available cores is', num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_sent(para): \n",
    "    para = re.sub('[\\\"\\']', '', para)\n",
    "    para = re.sub('([｡。.！？\\?])([^”’])', r\"\\1\\n\\2\", para)\n",
    "    para = re.sub('(\\.{6})([^”’])', r\"\\1\\n\\2\", para)\n",
    "    para = re.sub('(\\…{2})([^”’])', r\"\\1\\n\\2\", para)\n",
    "    para = re.sub('([。！？\\?\\…\\.]+[”’])([^，.。！？\\?])', r'\\1\\n\\2', para)\n",
    "    para = para.rstrip()\n",
    "    return para.split(\"\\n\")\n",
    "\n",
    "\n",
    "def clean_sent(sent): \n",
    "    remove = str.maketrans('○〇', '零零', string.punctuation) \n",
    "    sent = sent.translate(remove)\n",
    "    sent = re.sub('[{}]+'.format(punctuation + non_stops), '', sent)\n",
    "    return sent.strip()\n",
    "\n",
    "\n",
    "def tokenize_sent(sent, min_token_length=2): \n",
    "    line = ' '.join([token for token in jieba.cut(clean_sent(sent), use_paddle=False) if token != ' ' and len(token) >= min_token_length])\n",
    "    return line\n",
    "\n",
    "\n",
    "def join_para_tokens(para_tokens): \n",
    "    return '\\n'.join(list(dask.compute(*para_tokens)))\n",
    "\n",
    "def tokenize_para(text): \n",
    "    para_tokens = []\n",
    "    for para in text:\n",
    "        for sent in cut_sent(para):\n",
    "            para_tokens.append(tokenize_sent(sent))\n",
    "    #     return dask.delayed(join_para_tokens)(para_tokens)\n",
    "    return para_tokens\n",
    "\n",
    "def write_tokens_to_file(file_tokens): \n",
    "    with open(tokens_path, 'w') as fh_w: \n",
    "        for para_tokens in file_tokens: \n",
    "            fh_w.write(para_tokens)\n",
    "            fh_w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the main func for corpus load and processing\n",
    "\n",
    "def loadcorpus_plus_cleaning(corpus_name):\n",
    "\n",
    "    texts_raw = {'year': [], 'month': [], 'date': [],\n",
    "                 'issue': [], 'zhuan_lan': [], 'title': [],\n",
    "                 'author': [], 'raw_para':[],'token_para':[],'token_sent':[]}\n",
    "\n",
    "    count = 0\n",
    "    folders = sorted(os.listdir(corpus_name + \"/\"))\n",
    "    \n",
    "    # filter the year to 1965-1995\n",
    "    year_list=[str(x) for x in range(1965,1996)]\n",
    "    folders_filter=sorted([x for x in folders if x[:4] in year_list])\n",
    " \n",
    "    for folder in folders_filter:\n",
    "        if '7z' not in folder and '1988' in folder:\n",
    "            count += 1\n",
    "            print('Current running on {}, total: {}/372'.format(folder,\n",
    "                                                                count), end='\\r', flush=True)\n",
    "            #os.system('cd '+corpus_name+'/'+folder)\n",
    "            #os.system('find . -name \"*.DS_Store\" -type f -delete')\n",
    "\n",
    "            for file in os.listdir(corpus_name + \"/\" + folder + '/'):\n",
    "                if 'md' in file:\n",
    "\n",
    "                    # load in raw text\n",
    "\n",
    "                    news_piece = []\n",
    "                    news_loc = corpus_name + \"/\" + folder + '/'\n",
    "                    f = open(news_loc + file)\n",
    "                    for line in f:\n",
    "                        news_piece.append(line)\n",
    "\n",
    "                    # fill the info this news piece with cleaning\n",
    "\n",
    "                    # dates\n",
    "                    texts_raw['year'].append(str(folder)[:4])\n",
    "                    texts_raw['month'].append(str(folder)[5:7])\n",
    "                    texts_raw['date'].append(re.sub('\\n', '', news_piece[2]))\n",
    "\n",
    "                    # issue (第x版)\n",
    "                    # some issues have extended infomation, just keep them here\n",
    "                    issue_raw = re.sub('\\n', '', news_piece[3])\n",
    "                    if '第版' in issue_raw:\n",
    "                        texts_raw['issue'].append('NA')\n",
    "                    else:\n",
    "                        if issue_raw.index(')') - issue_raw.index('(') == 1:\n",
    "                            texts_raw['issue'].append(\n",
    "                                str(re.search(r'\\d+', issue_raw).group(0)))\n",
    "                        else:\n",
    "                            temp = issue_raw.index('(')\n",
    "                            texts_raw['issue'].append(clean_sent(\n",
    "                                str(re.search(r'\\d+', issue_raw).group(0)) + '_' + issue_raw[temp + 1:-1])[0])\n",
    "\n",
    "                    # zhuan_lan\n",
    "                    clean_zhuanlan = re.sub('\\n', '', news_piece[4])[3:]\n",
    "                    if clean_zhuanlan.strip() == '':\n",
    "                        texts_raw['zhuan_lan'].append('NA')\n",
    "                    else:\n",
    "                        texts_raw['zhuan_lan'].append(\n",
    "                            clean_sent(clean_zhuanlan)[0])\n",
    "\n",
    "                    # title\n",
    "                    clean_title_list = re.sub(\n",
    "                        '\\n', '', news_piece[0])[4:].split()\n",
    "                    clean_title_list = list(\n",
    "                        filter(lambda x: x != '', clean_title_list))\n",
    "                    clean_title = '_'.join(clean_title_list)\n",
    "                    texts_raw['title'].append(\n",
    "                        clean_sent(clean_title)[0])\n",
    "\n",
    "                    # authors\n",
    "                    author_str = ''\n",
    "                    author_list = []\n",
    "                    if news_piece[1] == '\\n':\n",
    "                        author_str = 'NA'\n",
    "                    else:\n",
    "                        author_list = re.sub('\\n', '', news_piece[1]).split()\n",
    "                        author_str = '_'.join(author_list)\n",
    "\n",
    "                    texts_raw['author'].append(\n",
    "                        clean_sent(author_str)[0])\n",
    "\n",
    "                    # texts\n",
    "                    author_title_list = [clean_title_list, author_list]\n",
    "                    cleaned_text = text_cleaning(\n",
    "                        author_title_list, news_piece[6:])\n",
    "                    if cleaned_text[1] == True:\n",
    "                        texts_raw['raw_para'].append(\n",
    "                            [clean_sent(x) for x in cleaned_text[0]])\n",
    "                        texts_raw['token_para'].append(tokenize_para(cleaned_text[0]))\n",
    "                        #print(texts_raw['token_para'][-1])\n",
    "                        texts_raw['token_sent'].append([sent.split() for sent in texts_raw['token_para'][-1]])\n",
    "                        \n",
    "                    else:\n",
    "                        # if return empty text, then this news piece is\n",
    "                        # trivial, just delete it\n",
    "                        del texts_raw['year'][-1]\n",
    "                        del texts_raw['month'][-1]\n",
    "                        del texts_raw['date'][-1]\n",
    "                        del texts_raw['issue'][-1]\n",
    "                        del texts_raw['zhuan_lan'][-1]\n",
    "                        del texts_raw['title'][-1]\n",
    "                        del texts_raw['author'][-1]\n",
    "                break\n",
    "            break\n",
    "    return texts_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the func for text body cleaning\n",
    "\n",
    "\n",
    "def text_cleaning(lists, text):\n",
    "\n",
    "    clean_text = [re.sub('\\n', '', x).strip() for x in text if x != '\\n']\n",
    "    title, authors = lists\n",
    "\n",
    "    # clean overlap title\n",
    "    for title_piece in title:\n",
    "        for sent in clean_text[:10]:\n",
    "            if title_piece in sent and len(title_piece) + 1 > len(sent):\n",
    "                clean_text[clean_text.index(sent)] = sent[\n",
    "                    sent.index(title_piece) + len(title_piece):]\n",
    "            elif sent in title_piece:\n",
    "                clean_text[clean_text.index(sent)] = ''\n",
    "\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    # if after cleaning the list goes empty, then return False to show this\n",
    "    # news is trivial (same below)\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # clean overlap authors at the beginning\n",
    "    for author_piece in authors:\n",
    "        if author_piece in clean_text[0]:\n",
    "            clean_text[0] = clean_text[0][clean_text[0].index(\n",
    "                author_piece) + len(author_piece) + 1:]\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # clean overlap authors at the end\n",
    "    for author_piece in authors:\n",
    "        if author_piece in clean_text[-1]:\n",
    "            ind = clean_text[-1].rfind('.')\n",
    "            if ind == -1:\n",
    "                clean_text = clean_text[:-1]\n",
    "                break\n",
    "            else:\n",
    "                clean_text[-1] = clean_text[-1][:ind + 1]\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # cleaning ‘【】’,like【新华社电讯】,etc.\n",
    "    if '【' in clean_text[0][:20]:\n",
    "        clean_text[0] = clean_text[0][clean_text[0].index('】') + 1:]\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # cleaning the irrelevant parathesis at the beginning\n",
    "    if '（' in clean_text[0][:25] and len(clean_text) > 1:\n",
    "        if '）' in clean_text[0]:\n",
    "            clean_text[0] = clean_text[0][clean_text[0].index('）') + 1:]\n",
    "        elif '）' in clean_text[1] and '（' not in clean_text[0]:\n",
    "            clean_text = clean_text[1:]\n",
    "            clean_text[0] = clean_text[0][clean_text[0].index('）') + 1:]\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # cleaning the irrelevant colons at the beginning like “新华社报讯:”\n",
    "    if '：' in clean_text[0][:20]:\n",
    "        clean_text[0] = clean_text[0][clean_text[0].index('：') + 1:]\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # cleaning the irrelevant info at the beginning like “新华社电”\n",
    "    if '新华社' in clean_text[0][:50]:\n",
    "        if '电' in clean_text[0][:50]:\n",
    "            clean_text[0] = clean_text[0][clean_text[0].index('电') + 1:]\n",
    "        elif '讯' in clean_text[0][:50]:\n",
    "            clean_text[0] = clean_text[0][clean_text[0].index('讯') + 1:]\n",
    "\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # cleaning the irrelevant info at the beginning like “本报讯”\n",
    "    if '本报讯' in clean_text[0][:50]:\n",
    "        clean_text[0] = clean_text[0][clean_text[0].index('讯') + 1:]\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # cleaning the irrelevant info at the end like “新华社稿”\n",
    "    if '（' in clean_text[-1][-15:]:\n",
    "        clean_text[-1] = clean_text[-1][:clean_text[-1].index('（')]\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    # cleaning the irrelevant info at the end like “新华社摄”\n",
    "    if '摄' in clean_text[-1][-20:] and '记者' in clean_text[-1][-20:]:\n",
    "        ind = clean_text[-1].rfind('.')\n",
    "        if ind == -1:\n",
    "            clean_text = clean_text[:-1]\n",
    "        else:\n",
    "            clean_text[-1] = clean_text[-1][:ind + 1]\n",
    "    clean_text = list(filter(lambda x: x != '', clean_text))\n",
    "\n",
    "    if len(clean_text) == 0:\n",
    "        return clean_text, False\n",
    "\n",
    "    return clean_text, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current running on 1988年01月, total: 1/372\n",
      "Total time used:  0.010367154000050505 s\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "news_raw = loadcorpus_plus_cleaning(corpus_name)\n",
    "\n",
    "running_time = timeit.default_timer() - start_time\n",
    "\n",
    "if running_time < 60:\n",
    "    print('\\nTotal time used: ', running_time, 's')\n",
    "else:\n",
    "    print('\\nTotal time used: ', running_time //\n",
    "          60, 'min', running_time % 60, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['中水技术开发和利用研究最近由北京市市政设计院完成',\n",
       "  '中水即指非饮用的中间自来水这项以污水资源化为战略目标的科研设计综合解决了开源和控制污染双重问题为水资源匮乏的大城市供水提供了可行方案',\n",
       "  '我国许多大城市水资源不足一些发达国家早就在开发大城市污水的回用研究但多数方案都因工艺复杂投资太高而很少实施北京市政府为妥善处理日益加快的建设速度和供水不足的矛盾1986年作出规定2万平方米以上的公共建筑必须设置中水设施否则不准兴建',\n",
       "  '中水技术开发和利用研究是配合北京新建的方庄小区污水回用工程而立项的专家认为方案采用的深度处理系统性强是目前国内最好的办法强化消毒新技术使水病毒消除率达999在国际上也属领先水平其工作周期长纳污量大更是我国独具的特色为验证设计的可靠性研究设计人员先在北京市结核病院和首都机场搞了两个示范工程经半年多运行都获得年节水量74万吨的效益']]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_raw['raw_para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['技术开发 利用 研究 最近 北京市 市政 设计院 完成',\n",
       "  '中水 指非 饮用 中间 自来水',\n",
       "  '这项 污水 资源 化为 战略目标 科研 设计 综合 解决 开源 控制 污染 双重 问题 水资源 匮乏 大城市 供水 提供 可行 方案',\n",
       "  '我国 许多 大城市 水资源 不足',\n",
       "  '一些 发达国家 早就 开发 城市污水 回用 研究 多数 方案 工艺 复杂 投资 太高 很少 实施',\n",
       "  '北京市政府 妥善处理 日益 加快 建设 速度 供水 不足 矛盾 1986 作出 规定 万平方米 以上 公共建筑 必须 设置 设施 否则 不准 兴建',\n",
       "  '技术开发 利用 研究 配合 北京 新建 方庄 小区 污水 工程 立项',\n",
       "  '专家 认为 方案 采用 深度 处理 系统性 强是 目前 国内 最好 办法 强化 消毒 技术 使水 病毒 消除 率达 99',\n",
       "  '国际 领先水平 工作 周期长 纳污量 更是 我国 独具 特色',\n",
       "  '验证 设计 可靠性 研究 设计 人员 北京市 结核病 首都机场 两个 示范 工程 半年 运行 获得 年节 水量',\n",
       "  '万吨 效益']]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_raw['token_para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['技术开发', '利用', '研究', '最近', '北京市', '市政', '设计院', '完成'],\n",
       "  ['中水', '指非', '饮用', '中间', '自来水'],\n",
       "  ['这项',\n",
       "   '污水',\n",
       "   '资源',\n",
       "   '化为',\n",
       "   '战略目标',\n",
       "   '科研',\n",
       "   '设计',\n",
       "   '综合',\n",
       "   '解决',\n",
       "   '开源',\n",
       "   '控制',\n",
       "   '污染',\n",
       "   '双重',\n",
       "   '问题',\n",
       "   '水资源',\n",
       "   '匮乏',\n",
       "   '大城市',\n",
       "   '供水',\n",
       "   '提供',\n",
       "   '可行',\n",
       "   '方案'],\n",
       "  ['我国', '许多', '大城市', '水资源', '不足'],\n",
       "  ['一些',\n",
       "   '发达国家',\n",
       "   '早就',\n",
       "   '开发',\n",
       "   '城市污水',\n",
       "   '回用',\n",
       "   '研究',\n",
       "   '多数',\n",
       "   '方案',\n",
       "   '工艺',\n",
       "   '复杂',\n",
       "   '投资',\n",
       "   '太高',\n",
       "   '很少',\n",
       "   '实施'],\n",
       "  ['北京市政府',\n",
       "   '妥善处理',\n",
       "   '日益',\n",
       "   '加快',\n",
       "   '建设',\n",
       "   '速度',\n",
       "   '供水',\n",
       "   '不足',\n",
       "   '矛盾',\n",
       "   '1986',\n",
       "   '作出',\n",
       "   '规定',\n",
       "   '万平方米',\n",
       "   '以上',\n",
       "   '公共建筑',\n",
       "   '必须',\n",
       "   '设置',\n",
       "   '设施',\n",
       "   '否则',\n",
       "   '不准',\n",
       "   '兴建'],\n",
       "  ['技术开发', '利用', '研究', '配合', '北京', '新建', '方庄', '小区', '污水', '工程', '立项'],\n",
       "  ['专家',\n",
       "   '认为',\n",
       "   '方案',\n",
       "   '采用',\n",
       "   '深度',\n",
       "   '处理',\n",
       "   '系统性',\n",
       "   '强是',\n",
       "   '目前',\n",
       "   '国内',\n",
       "   '最好',\n",
       "   '办法',\n",
       "   '强化',\n",
       "   '消毒',\n",
       "   '技术',\n",
       "   '使水',\n",
       "   '病毒',\n",
       "   '消除',\n",
       "   '率达',\n",
       "   '99'],\n",
       "  ['国际', '领先水平', '工作', '周期长', '纳污量', '更是', '我国', '独具', '特色'],\n",
       "  ['验证',\n",
       "   '设计',\n",
       "   '可靠性',\n",
       "   '研究',\n",
       "   '设计',\n",
       "   '人员',\n",
       "   '北京市',\n",
       "   '结核病',\n",
       "   '首都机场',\n",
       "   '两个',\n",
       "   '示范',\n",
       "   '工程',\n",
       "   '半年',\n",
       "   '运行',\n",
       "   '获得',\n",
       "   '年节',\n",
       "   '水量'],\n",
       "  ['万吨', '效益']]]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_raw['token_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>issue</th>\n",
       "      <th>zhuan_lan</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>raw_para</th>\n",
       "      <th>token_para</th>\n",
       "      <th>token_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988</td>\n",
       "      <td>01</td>\n",
       "      <td>1988-01-06</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>北</td>\n",
       "      <td>艾</td>\n",
       "      <td>[中水技术开发和利用研究最近由北京市市政设计院完成, 中水即指非饮用的中间自来水这项以污水资...</td>\n",
       "      <td>[技术开发 利用 研究 最近 北京市 市政 设计院 完成, 中水 指非 饮用 中间 自来水,...</td>\n",
       "      <td>[[技术开发, 利用, 研究, 最近, 北京市, 市政, 设计院, 完成], [中水, 指非...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month        date issue zhuan_lan title author  \\\n",
       "0  1988    01  1988-01-06     3        NA     北      艾   \n",
       "\n",
       "                                            raw_para  \\\n",
       "0  [中水技术开发和利用研究最近由北京市市政设计院完成, 中水即指非饮用的中间自来水这项以污水资...   \n",
       "\n",
       "                                          token_para  \\\n",
       "0  [技术开发 利用 研究 最近 北京市 市政 设计院 完成, 中水 指非 饮用 中间 自来水,...   \n",
       "\n",
       "                                          token_sent  \n",
       "0  [[技术开发, 利用, 研究, 最近, 北京市, 市政, 设计院, 完成], [中水, 指非...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transfer to df\n",
    "\n",
    "news_df = pd.DataFrame(news_raw)\n",
    "news_df_sort = news_df.sort_values(['date', 'issue'])\n",
    "news_df_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>issue</th>\n",
       "      <th>zhuan_lan</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>05</td>\n",
       "      <td>1946-05-15</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>沁县阎军特务横行_殴劫我联络组人员_我已向东沁线小组提出抗议</td>\n",
       "      <td>NA</td>\n",
       "      <td>[白晋线阎军伪造所谓\"控诉共党罪行\",已在沁县城内演出殴打中共联络组人员事件.四月三十日晚,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150676</th>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>1956-11-10</td>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "      <td>要求英法侵略者立即撤出埃及领土</td>\n",
       "      <td>NA</td>\n",
       "      <td>[全国各地人民,继续进行各种活动热烈支援埃及反抗英法侵略,要求侵略者立即撤出埃及领土.正在北...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300284</th>\n",
       "      <td>1963</td>\n",
       "      <td>09</td>\n",
       "      <td>1963-09-12</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>应邀出席世界科协北京中心会议_古巴两客人抵京</td>\n",
       "      <td>NA</td>\n",
       "      <td>[应中华人民共和国科学技术协会和世界科协北京中心邀请,来北京参加世界科协北京中心第一次科学讨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450708</th>\n",
       "      <td>1975</td>\n",
       "      <td>10</td>\n",
       "      <td>1975-10-06</td>\n",
       "      <td>4</td>\n",
       "      <td>NA</td>\n",
       "      <td>扎伊尔总统蒙博托的贺电</td>\n",
       "      <td>NA</td>\n",
       "      <td>[扎伊尔总统蒙博托的贺电中国共产党中央委员会主席毛泽东先生阁下主席先生:, 在英勇的中国人民...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599720</th>\n",
       "      <td>1983</td>\n",
       "      <td>04</td>\n",
       "      <td>1983-04-18</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>赵总理离新西兰抵澳大利亚访问_到堪培拉时,霍克总理到机场迎接并设宴欢迎_离奥克兰时,马尔登总...</td>\n",
       "      <td>NA</td>\n",
       "      <td>[中国国务院总理赵紫阳应澳大利亚总理霍克的邀请,今天下午抵达澳大利亚首都堪培拉,开始对澳大利...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750049</th>\n",
       "      <td>1987</td>\n",
       "      <td>12</td>\n",
       "      <td>1987-12-15</td>\n",
       "      <td>6_国际</td>\n",
       "      <td>NA</td>\n",
       "      <td>法国总理希拉克主张树立欧洲防务思想_卡卢奇说中导条约不会使欧美防务脱钩</td>\n",
       "      <td>NA</td>\n",
       "      <td>[法国总理希拉克主张树立欧洲防务思想  卡卢奇说中导条约不会使欧美防务脱钩, 新华社巴黎12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901398</th>\n",
       "      <td>1992</td>\n",
       "      <td>09</td>\n",
       "      <td>1992-09-14</td>\n",
       "      <td>3_教育·科技·文化</td>\n",
       "      <td>大学生暑假见闻征文</td>\n",
       "      <td>向西的突破</td>\n",
       "      <td>康新明</td>\n",
       "      <td>[走在乌鲁木齐市红山市场,不时发现有些身材高大\\留着卷曲胡须的独联体游客在兜售他们的商品.从...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050474</th>\n",
       "      <td>1997</td>\n",
       "      <td>04</td>\n",
       "      <td>1997-04-02</td>\n",
       "      <td>10_文化</td>\n",
       "      <td>NA</td>\n",
       "      <td>电脑设计忽如一夜春风来图书装帧面临\"换笔\"</td>\n",
       "      <td>李桂杰</td>\n",
       "      <td>[流连于大大小小的书店或书摊,稍稍留意,你会发现近一两年出版的书籍在装帧设计上比过去要精美漂...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200734</th>\n",
       "      <td>2002</td>\n",
       "      <td>01</td>\n",
       "      <td>2002-01-16</td>\n",
       "      <td>12_民就与监督</td>\n",
       "      <td>NA</td>\n",
       "      <td>南江严把乡镇换届\"九道关\"</td>\n",
       "      <td>冉峥嵘</td>\n",
       "      <td>[针对乡镇人大换届选举工作法律性\\政策性\\程序性要求严格的情况,四川省南江县在乡镇人大换届选...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year month        date       issue  zhuan_lan  \\\n",
       "3        1946    05  1946-05-15           1         NA   \n",
       "150676   1956    11  1956-11-10           2         NA   \n",
       "300284   1963    09  1963-09-12           3         NA   \n",
       "450708   1975    10  1975-10-06           4         NA   \n",
       "599720   1983    04  1983-04-18           1         NA   \n",
       "750049   1987    12  1987-12-15        6_国际         NA   \n",
       "901398   1992    09  1992-09-14  3_教育·科技·文化  大学生暑假见闻征文   \n",
       "1050474  1997    04  1997-04-02       10_文化         NA   \n",
       "1200734  2002    01  2002-01-16    12_民就与监督         NA   \n",
       "\n",
       "                                                     title author  \\\n",
       "3                           沁县阎军特务横行_殴劫我联络组人员_我已向东沁线小组提出抗议     NA   \n",
       "150676                                     要求英法侵略者立即撤出埃及领土     NA   \n",
       "300284                              应邀出席世界科协北京中心会议_古巴两客人抵京     NA   \n",
       "450708                                         扎伊尔总统蒙博托的贺电     NA   \n",
       "599720   赵总理离新西兰抵澳大利亚访问_到堪培拉时,霍克总理到机场迎接并设宴欢迎_离奥克兰时,马尔登总...     NA   \n",
       "750049                 法国总理希拉克主张树立欧洲防务思想_卡卢奇说中导条约不会使欧美防务脱钩     NA   \n",
       "901398                                               向西的突破    康新明   \n",
       "1050474                              电脑设计忽如一夜春风来图书装帧面临\"换笔\"    李桂杰   \n",
       "1200734                                      南江严把乡镇换届\"九道关\"    冉峥嵘   \n",
       "\n",
       "                                                      text  \n",
       "3        [白晋线阎军伪造所谓\"控诉共党罪行\",已在沁县城内演出殴打中共联络组人员事件.四月三十日晚,...  \n",
       "150676   [全国各地人民,继续进行各种活动热烈支援埃及反抗英法侵略,要求侵略者立即撤出埃及领土.正在北...  \n",
       "300284   [应中华人民共和国科学技术协会和世界科协北京中心邀请,来北京参加世界科协北京中心第一次科学讨...  \n",
       "450708   [扎伊尔总统蒙博托的贺电中国共产党中央委员会主席毛泽东先生阁下主席先生:, 在英勇的中国人民...  \n",
       "599720   [中国国务院总理赵紫阳应澳大利亚总理霍克的邀请,今天下午抵达澳大利亚首都堪培拉,开始对澳大利...  \n",
       "750049   [法国总理希拉克主张树立欧洲防务思想  卡卢奇说中导条约不会使欧美防务脱钩, 新华社巴黎12...  \n",
       "901398   [走在乌鲁木齐市红山市场,不时发现有些身材高大\\留着卷曲胡须的独联体游客在兜售他们的商品.从...  \n",
       "1050474  [流连于大大小小的书店或书摊,稍稍留意,你会发现近一两年出版的书籍在装帧设计上比过去要精美漂...  \n",
       "1200734  [针对乡镇人大换届选举工作法律性\\政策性\\程序性要求严格的情况,四川省南江县在乡镇人大换届选...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random check on df\n",
    "\n",
    "news_df_sort[::150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample output the corpus to csv\n",
    "if user == \"Tim\":\n",
    "    saving_path = \"/Users/timqzhang/Desktop/UChicago/MACSS_Spring_2020/content_local/rmrb/\"\n",
    "elif user == \"Linghui\":\n",
    "    saving_path = \"/Users/linghuiwu/uchicago/courseworks/soci40133/rmrb/\"\n",
    "elif user == \"Minghao\":\n",
    "    saving_path = \"to be filled\"\n",
    "\n",
    "news_df_sort[news_df_sort['year']=='1984'][22000:24000].to_csv(saving_path + \"rmrb_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample filtering (pic news here)\n",
    "\n",
    "news_df_filter=news_df_sort[~news_df_sort.title.str.contains('(图片)')==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>issue</th>\n",
       "      <th>zhuan_lan</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>05</td>\n",
       "      <td>1946-05-15</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>沁县阎军特务横行_殴劫我联络组人员_我已向东沁线小组提出抗议</td>\n",
       "      <td>NA</td>\n",
       "      <td>[白晋线阎军伪造所谓\"控诉共党罪行\",已在沁县城内演出殴打中共联络组人员事件.四月三十日晚,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1946</td>\n",
       "      <td>05</td>\n",
       "      <td>1946-05-15</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>周徐白三氏飞南京_光山小组将视察中原解放区</td>\n",
       "      <td>NA</td>\n",
       "      <td>[中共代表周恩来\\美方代表白鲁德\\及徐永昌代表王天鸣等一行,九日下午由宣化店返抵汉口后,周\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1946</td>\n",
       "      <td>05</td>\n",
       "      <td>1946-05-15</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>发刊词</td>\n",
       "      <td>NA</td>\n",
       "      <td>[本报-人民日报,晋冀鲁豫边区广大人民的报纸出版了., 晋冀鲁豫边区的人民\\八路军\\共产党在...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1946</td>\n",
       "      <td>05</td>\n",
       "      <td>1946-05-15</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>平汉川陕道上国民党军运忙</td>\n",
       "      <td>NA</td>\n",
       "      <td>[平汉路上军车辚辚,日前国民党军由新乡运抵辉县坦克十六辆重炮五门.晋豫地区国民党军,正积极进...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1946</td>\n",
       "      <td>05</td>\n",
       "      <td>1946-05-15</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>国民党军结合敌伪高唱备战_大举调动屡犯我边区_三个半月大小进攻九百余次</td>\n",
       "      <td>NA</td>\n",
       "      <td>[国民党军结合敌伪军,高唱\"停战就是备战\",\"整军就是建军\",\"复员就是动员\",乘八路军忠实...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269241</th>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>9_文化新闻</td>\n",
       "      <td>文事评点</td>\n",
       "      <td>对租书摊的管理不容忽视</td>\n",
       "      <td>陈晓东</td>\n",
       "      <td>[现在有许多租书摊点遍布城镇的大街小巷,租书摊的图书一般品种比较多,价格也不贵,花一两角钱就...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269316</th>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>9_文化新闻</td>\n",
       "      <td>NA</td>\n",
       "      <td>给孩子一片绿色文化的天地-中央电视台少儿频道开播小记</td>\n",
       "      <td>向兵</td>\n",
       "      <td>[这里是中央电视台少儿频道.\"2003年12月28日清晨6时,随着人们早已熟悉的中央电视台开...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269676</th>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>9_文化新闻</td>\n",
       "      <td>文化在线</td>\n",
       "      <td>安塞举办\"陕北过大年\"摄影活动</td>\n",
       "      <td>师银笙</td>\n",
       "      <td>[由中国艺术摄影协会,安塞县委\\县政府主办的\"陕北过大年\"摄影创作活动将于2004年正月十二...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269974</th>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>9_文化新闻</td>\n",
       "      <td>文化在线</td>\n",
       "      <td>精品剧目冠名授牌仪式在京举行</td>\n",
       "      <td>陈斯</td>\n",
       "      <td>[国家舞台艺术精品工程2002—2003年度十大精品剧目和20台精品提名剧目的冠名授牌仪式,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270121</th>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>9_文化新闻</td>\n",
       "      <td>NA</td>\n",
       "      <td>平顶山广泛开展社区文化活动</td>\n",
       "      <td>古国凡</td>\n",
       "      <td>[河南省平顶山市卫东区是国家民政部授予的\"全国社区建设示范城区\".全区35个社区有文艺表演队...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238647 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year month        date   issue zhuan_lan  \\\n",
       "3        1946    05  1946-05-15       1        NA   \n",
       "73       1946    05  1946-05-15       1        NA   \n",
       "112      1946    05  1946-05-15       1        NA   \n",
       "136      1946    05  1946-05-15       1        NA   \n",
       "153      1946    05  1946-05-15       1        NA   \n",
       "...       ...   ...         ...     ...       ...   \n",
       "1269241  2003    12  2003-12-31  9_文化新闻      文事评点   \n",
       "1269316  2003    12  2003-12-31  9_文化新闻        NA   \n",
       "1269676  2003    12  2003-12-31  9_文化新闻      文化在线   \n",
       "1269974  2003    12  2003-12-31  9_文化新闻      文化在线   \n",
       "1270121  2003    12  2003-12-31  9_文化新闻        NA   \n",
       "\n",
       "                                       title author  \\\n",
       "3             沁县阎军特务横行_殴劫我联络组人员_我已向东沁线小组提出抗议     NA   \n",
       "73                     周徐白三氏飞南京_光山小组将视察中原解放区     NA   \n",
       "112                                      发刊词     NA   \n",
       "136                             平汉川陕道上国民党军运忙     NA   \n",
       "153      国民党军结合敌伪高唱备战_大举调动屡犯我边区_三个半月大小进攻九百余次     NA   \n",
       "...                                      ...    ...   \n",
       "1269241                          对租书摊的管理不容忽视    陈晓东   \n",
       "1269316           给孩子一片绿色文化的天地-中央电视台少儿频道开播小记     向兵   \n",
       "1269676                      安塞举办\"陕北过大年\"摄影活动    师银笙   \n",
       "1269974                       精品剧目冠名授牌仪式在京举行     陈斯   \n",
       "1270121                        平顶山广泛开展社区文化活动    古国凡   \n",
       "\n",
       "                                                      text  \n",
       "3        [白晋线阎军伪造所谓\"控诉共党罪行\",已在沁县城内演出殴打中共联络组人员事件.四月三十日晚,...  \n",
       "73       [中共代表周恩来\\美方代表白鲁德\\及徐永昌代表王天鸣等一行,九日下午由宣化店返抵汉口后,周\\...  \n",
       "112      [本报-人民日报,晋冀鲁豫边区广大人民的报纸出版了., 晋冀鲁豫边区的人民\\八路军\\共产党在...  \n",
       "136      [平汉路上军车辚辚,日前国民党军由新乡运抵辉县坦克十六辆重炮五门.晋豫地区国民党军,正积极进...  \n",
       "153      [国民党军结合敌伪军,高唱\"停战就是备战\",\"整军就是建军\",\"复员就是动员\",乘八路军忠实...  \n",
       "...                                                    ...  \n",
       "1269241  [现在有许多租书摊点遍布城镇的大街小巷,租书摊的图书一般品种比较多,价格也不贵,花一两角钱就...  \n",
       "1269316  [这里是中央电视台少儿频道.\"2003年12月28日清晨6时,随着人们早已熟悉的中央电视台开...  \n",
       "1269676  [由中国艺术摄影协会,安塞县委\\县政府主办的\"陕北过大年\"摄影创作活动将于2004年正月十二...  \n",
       "1269974  [国家舞台艺术精品工程2002—2003年度十大精品剧目和20台精品提名剧目的冠名授牌仪式,...  \n",
       "1270121  [河南省平顶山市卫东区是国家民政部授予的\"全国社区建设示范城区\".全区35个社区有文艺表演队...  \n",
       "\n",
       "[1238647 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the whole corpus for further analysis\n",
    "if user == \"Linghui\":\n",
    "    news_df_filter.to_csv(\"rmrb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
